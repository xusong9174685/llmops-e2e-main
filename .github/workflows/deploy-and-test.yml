name: Deploy and Test on kind

# Trigger manually or after Trivy Remote Scan completes
on:
  workflow_dispatch:
  workflow_run:
    workflows: ["Trivy Remote Scan"]
    types: [completed]

jobs:
  deploy-and-test:
    runs-on: ubuntu-latest
    if: ${{ github.event.workflow_run.conclusion == 'success' }}

    steps:
      # 1. Checkout repo
      - name: Checkout code
        uses: actions/checkout@v4

      # 2. Install kind
      - name: Install kind
        run: |
          curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.25.0/kind-linux-amd64
          chmod +x ./kind
          sudo mv ./kind /usr/local/bin/kind

      # 3. Start kind cluster
      - name: Start kind cluster
        run: kind create cluster --name github-ci

      # 4. Install kubectl
      - name: Setup kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: latest

      # 5. Load Docker image into kind
      - name: Load Docker image into kind
        run: |
          docker pull xusonglin/fastapi-app:latest
          kind load docker-image xusonglin/fastapi-app:latest --name github-ci

      # 6. Adjust deployment replicas for CI/CD (optional)
      - name: Set replicas to 1 for CI/CD
        run: |
          kubectl scale deployment gpt-huggingface --replicas=1 || true

      # 7. Deploy app
      - name: Deploy app to kind
        run: |
          kubectl apply -f deployment.yaml
          kubectl apply -f service.yaml

      # 8. Wait for pods to be ready
      - name: Wait for pod readiness
        run: |
          kubectl wait --for=condition=ready pod -l app=gpt-hf-pod --timeout=300s

      # 9. Port-forward and test API
      - name: Port-forward and test API
        run: |
          # Start port-forward in background
          kubectl port-forward svc/gpt-hf-service 8000:8000 &
          PF_PID=$!
          echo "Port-forward PID: $PF_PID"

          # Wait until service responds
          echo "Waiting for FastAPI service..."
          for i in {1..30}; do
            if curl -s http://localhost:8000/ > /dev/null; then
              echo "Service is up!"
              break
            fi
            echo "Still waiting..."
            sleep 2
          done

          # Test API endpoint with question + answer
          curl --fail -X POST http://localhost:8000/chat \
            -H "Content-Type: application/json" \
            -d '{"question": "What does Hugging Face provides?", "answer": "Hugging Face is a technology company that provides open-source NLP libraries ..."}'

          # Kill port-forward
          kill $PF_PID

      # 10. Install kube-score
      - name: Install kube-score
        run: |
          curl -sLo kube-score.tar.gz https://github.com/zegl/kube-score/releases/download/v1.25.1/kube-score_1.25.1_linux_amd64.tar.gz
          tar -xzf kube-score.tar.gz kube-score
          sudo mv kube-score /usr/local/bin/

      # 11. Run kube-score
      - name: Run kube-score
        run: kube-score score --output-format ci deployment.yaml

      # 12. Cleanup kind cluster (optional)
      - name: Delete kind cluster
        if: always()
        run: kind delete cluster --name github-ci

      # 13. Debug pod logs if failure
      - name: Show pod logs on failure
        if: failure()
        run: |
          kubectl get pods
          kubectl logs -l app=gpt-hf-pod